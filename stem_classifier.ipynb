{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99989, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('C:\\\\Users\\\\guilh_000\\Documents\\\\tweetsclassify\\\\train.csv', encoding='latin-1')\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL friend.............</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trailer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!       T_T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>or i just worry too much?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunny Again        Work Tomorrow  :-|       TV Tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>handed in my uniform today . i miss you already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>hmmmm.... i wonder how she my number @-)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment  \\\n",
       "0       1          0   \n",
       "1       2          0   \n",
       "2       3          1   \n",
       "3       4          0   \n",
       "4       5          0   \n",
       "5       6          0   \n",
       "6       7          1   \n",
       "7       8          0   \n",
       "8       9          1   \n",
       "9      10          1   \n",
       "\n",
       "                                                                                         SentimentText  \n",
       "0                                                             is so sad for my APL friend.............  \n",
       "1                                                                     I missed the New Moon trailer...  \n",
       "2                                                                              omg its already 7:30 :O  \n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2...  \n",
       "4                                                         i think mi bf is cheating on me!!!       T_T  \n",
       "5                                                                    or i just worry too much?          \n",
       "6                                                                   Juuuuuuuuuuuuuuuuussssst Chillin!!  \n",
       "7                                               Sunny Again        Work Tomorrow  :-|       TV Tonight  \n",
       "8                                                      handed in my uniform today . i miss you already  \n",
       "9                                                             hmmmm.... i wonder how she my number @-)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    " \n",
    "from nltk.corpus import stopwords \n",
    "stopwords_english = stopwords.words('english')\n",
    "\n",
    "additional_stop_words = ['rt','via','...','http','twitpic','tinyurl','www', 'amp']\n",
    "stopwords_list = stopwords_english + additional_stop_words\n",
    " \n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    " \n",
    "from nltk.tokenize import TweetTokenizer\n",
    " \n",
    "# Happy Emoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    " \n",
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    " \n",
    "# all emoticons (happy + sad)\n",
    "emoticons = emoticons_happy.union(emoticons_sad)\n",
    " \n",
    "def clean_tweets(tweet):\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    " \n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    \n",
    "    #remove mentions and usernames\n",
    "    tweet = re.sub(\"(@[A-Za-z0-9]+)\", \" \", tweet)\n",
    " \n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    \n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    tweet= re.sub(\"[^a-zA-Z]\", \" \", tweet)\n",
    " \n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    " \n",
    "    tweets_clean = []    \n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_list and # remove stopwords\n",
    "              word not in emoticons and # remove emoticons\n",
    "                word not in string.punctuation): # remove punctuation\n",
    "            #tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word) # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    " \n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['normalized'] = train.SentimentText.apply(clean_tweets)\n",
    "train['normal'] = [' '.join(map(str, l)) for l in train['normalized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>normalized</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL friend.............</td>\n",
       "      <td>[sad, apl, friend]</td>\n",
       "      <td>sad apl friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trailer...</td>\n",
       "      <td>[miss, new, moon, trailer]</td>\n",
       "      <td>miss new moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>[omg, alreadi]</td>\n",
       "      <td>omg alreadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2...</td>\n",
       "      <td>[omgaga, im, sooo, im, gunna, cri, dentist, sinc, supos, get, crown, put, min]</td>\n",
       "      <td>omgaga im sooo im gunna cri dentist sinc supos get crown put min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!       T_T</td>\n",
       "      <td>[think, mi, bf, cheat]</td>\n",
       "      <td>think mi bf cheat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment  \\\n",
       "0       1          0   \n",
       "1       2          0   \n",
       "2       3          1   \n",
       "3       4          0   \n",
       "4       5          0   \n",
       "\n",
       "                                                                                         SentimentText  \\\n",
       "0                                                             is so sad for my APL friend.............   \n",
       "1                                                                     I missed the New Moon trailer...   \n",
       "2                                                                              omg its already 7:30 :O   \n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2...   \n",
       "4                                                         i think mi bf is cheating on me!!!       T_T   \n",
       "\n",
       "                                                                       normalized  \\\n",
       "0                                                              [sad, apl, friend]   \n",
       "1                                                      [miss, new, moon, trailer]   \n",
       "2                                                                  [omg, alreadi]   \n",
       "3  [omgaga, im, sooo, im, gunna, cri, dentist, sinc, supos, get, crown, put, min]   \n",
       "4                                                          [think, mi, bf, cheat]   \n",
       "\n",
       "                                                             normal  \n",
       "0                                                    sad apl friend  \n",
       "1                                             miss new moon trailer  \n",
       "2                                                       omg alreadi  \n",
       "3  omgaga im sooo im gunna cri dentist sinc supos get crown put min  \n",
       "4                                                 think mi bf cheat  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>normalized</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99969</th>\n",
       "      <td>99981</td>\n",
       "      <td>0</td>\n",
       "      <td>@CTerry1985  Sorry</td>\n",
       "      <td>[sorri]</td>\n",
       "      <td>sorri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99970</th>\n",
       "      <td>99982</td>\n",
       "      <td>0</td>\n",
       "      <td>@CTerry1985 damn it, dont have sky</td>\n",
       "      <td>[damn, dont, sky]</td>\n",
       "      <td>damn dont sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99971</th>\n",
       "      <td>99983</td>\n",
       "      <td>0</td>\n",
       "      <td>@CTerry1985 That's the thing; the new raft of Star Wars films were just a raft of #EpicFail s</td>\n",
       "      <td>[thing, new, raft, star, war, film, raft, epicfail]</td>\n",
       "      <td>thing new raft star war film raft epicfail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99972</th>\n",
       "      <td>99984</td>\n",
       "      <td>1</td>\n",
       "      <td>@cthagod</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973</th>\n",
       "      <td>99985</td>\n",
       "      <td>1</td>\n",
       "      <td>@ctham  #FollowFriday</td>\n",
       "      <td>[followfriday]</td>\n",
       "      <td>followfriday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99974</th>\n",
       "      <td>99986</td>\n",
       "      <td>0</td>\n",
       "      <td>@ctham #awaresg You are not wrong. But from a my own male point of view, I felt excluded (even w...</td>\n",
       "      <td>[awaresg, wrong, male, point, view, felt, exclud, even, non, repli, thread]</td>\n",
       "      <td>awaresg wrong male point view felt exclud even non repli thread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99975</th>\n",
       "      <td>99987</td>\n",
       "      <td>0</td>\n",
       "      <td>@ctham @mommyfizz cuz you big burly man.  hahahahahahahahaha</td>\n",
       "      <td>[cuz, big, burli, man, hahahahahahahahaha]</td>\n",
       "      <td>cuz big burli man hahahahahahahahaha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99976</th>\n",
       "      <td>99988</td>\n",
       "      <td>1</td>\n",
       "      <td>@ctham @Wilsurn Trying to get a wider range of shirts to suit everyone. Please make requests if ...</td>\n",
       "      <td>[tri, get, wider, rang, shirt, suit, everyon, pleas, make, request, need, awaresg]</td>\n",
       "      <td>tri get wider rang shirt suit everyon pleas make request need awaresg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99977</th>\n",
       "      <td>99989</td>\n",
       "      <td>1</td>\n",
       "      <td>@ctham Haha I love the passion in your support</td>\n",
       "      <td>[haha, love, passion, support]</td>\n",
       "      <td>haha love passion support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99978</th>\n",
       "      <td>99990</td>\n",
       "      <td>1</td>\n",
       "      <td>@cthulhullahoop That sucks...I like living in Coopersville, I don't need no special bags or anyt...</td>\n",
       "      <td>[suck, like, live, coopersvil, need, special, bag, anyth]</td>\n",
       "      <td>suck like live coopersvil need special bag anyth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99979</th>\n",
       "      <td>99991</td>\n",
       "      <td>1</td>\n",
       "      <td>@cunningstunts till i can go home been here till saturday  x</td>\n",
       "      <td>[till, go, home, till, saturday, x]</td>\n",
       "      <td>till go home till saturday x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99980</th>\n",
       "      <td>99992</td>\n",
       "      <td>1</td>\n",
       "      <td>@cunningstunts22 afternoon jim hows you  x</td>\n",
       "      <td>[afternoon, jim, how, x]</td>\n",
       "      <td>afternoon jim how x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99981</th>\n",
       "      <td>99993</td>\n",
       "      <td>0</td>\n",
       "      <td>@cup_a_tea The foot is really bad. Like the worst it's ever been. I can barely walk right now.</td>\n",
       "      <td>[tea, foot, realli, bad, like, worst, ever, bare, walk, right]</td>\n",
       "      <td>tea foot realli bad like worst ever bare walk right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99982</th>\n",
       "      <td>99994</td>\n",
       "      <td>1</td>\n",
       "      <td>@Cup_Of_Katy Have fun doing health &amp;amp; safety :S Just switch off and look spritely  XXX</td>\n",
       "      <td>[kati, fun, health, safeti, switch, look, sprite, xxx]</td>\n",
       "      <td>kati fun health safeti switch look sprite xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99983</th>\n",
       "      <td>99995</td>\n",
       "      <td>0</td>\n",
       "      <td>@cupati It took me waaay too long to get your message about being ashamed...right now I really a...</td>\n",
       "      <td>[took, waaay, long, get, messag, asham, right, realli, asham]</td>\n",
       "      <td>took waaay long get messag asham right realli asham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>99996</td>\n",
       "      <td>0</td>\n",
       "      <td>@Cupcake  seems like a repeating problem   hope you're able to find something.</td>\n",
       "      <td>[seem, like, repeat, problem, hope, abl, find, someth]</td>\n",
       "      <td>seem like repeat problem hope abl find someth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>99997</td>\n",
       "      <td>1</td>\n",
       "      <td>@cupcake__ arrrr we both replied to each other over different tweets at the same time  , i'll se...</td>\n",
       "      <td>[arrr, repli, differ, tweet, time, see, duno, hell, kateyi]</td>\n",
       "      <td>arrr repli differ tweet time see duno hell kateyi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>99998</td>\n",
       "      <td>0</td>\n",
       "      <td>@CuPcAkE_2120 ya i thought so</td>\n",
       "      <td>[ya, thought]</td>\n",
       "      <td>ya thought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>@Cupcake_Dollie Yes. Yes. I'm glad you had more fun with me.</td>\n",
       "      <td>[dolli, ye, ye, glad, fun]</td>\n",
       "      <td>dolli ye ye glad fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>@cupcake_kayla haha yes you do</td>\n",
       "      <td>[kayla, haha, ye]</td>\n",
       "      <td>kayla haha ye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID  Sentiment  \\\n",
       "99969   99981          0   \n",
       "99970   99982          0   \n",
       "99971   99983          0   \n",
       "99972   99984          1   \n",
       "99973   99985          1   \n",
       "99974   99986          0   \n",
       "99975   99987          0   \n",
       "99976   99988          1   \n",
       "99977   99989          1   \n",
       "99978   99990          1   \n",
       "99979   99991          1   \n",
       "99980   99992          1   \n",
       "99981   99993          0   \n",
       "99982   99994          1   \n",
       "99983   99995          0   \n",
       "99984   99996          0   \n",
       "99985   99997          1   \n",
       "99986   99998          0   \n",
       "99987   99999          1   \n",
       "99988  100000          1   \n",
       "\n",
       "                                                                                             SentimentText  \\\n",
       "99969                                                                                   @CTerry1985  Sorry   \n",
       "99970                                                                  @CTerry1985 damn it, dont have sky    \n",
       "99971       @CTerry1985 That's the thing; the new raft of Star Wars films were just a raft of #EpicFail s    \n",
       "99972                                                                                            @cthagod    \n",
       "99973                                                                                @ctham  #FollowFriday   \n",
       "99974  @ctham #awaresg You are not wrong. But from a my own male point of view, I felt excluded (even w...   \n",
       "99975                                         @ctham @mommyfizz cuz you big burly man.  hahahahahahahahaha   \n",
       "99976  @ctham @Wilsurn Trying to get a wider range of shirts to suit everyone. Please make requests if ...   \n",
       "99977                                                      @ctham Haha I love the passion in your support    \n",
       "99978  @cthulhullahoop That sucks...I like living in Coopersville, I don't need no special bags or anyt...   \n",
       "99979                                         @cunningstunts till i can go home been here till saturday  x   \n",
       "99980                                                           @cunningstunts22 afternoon jim hows you  x   \n",
       "99981      @cup_a_tea The foot is really bad. Like the worst it's ever been. I can barely walk right now.    \n",
       "99982            @Cup_Of_Katy Have fun doing health &amp; safety :S Just switch off and look spritely  XXX   \n",
       "99983  @cupati It took me waaay too long to get your message about being ashamed...right now I really a...   \n",
       "99984                       @Cupcake  seems like a repeating problem   hope you're able to find something.   \n",
       "99985  @cupcake__ arrrr we both replied to each other over different tweets at the same time  , i'll se...   \n",
       "99986                                                                       @CuPcAkE_2120 ya i thought so    \n",
       "99987                                        @Cupcake_Dollie Yes. Yes. I'm glad you had more fun with me.    \n",
       "99988                                                                      @cupcake_kayla haha yes you do    \n",
       "\n",
       "                                                                               normalized  \\\n",
       "99969                                                                             [sorri]   \n",
       "99970                                                                   [damn, dont, sky]   \n",
       "99971                                 [thing, new, raft, star, war, film, raft, epicfail]   \n",
       "99972                                                                                  []   \n",
       "99973                                                                      [followfriday]   \n",
       "99974         [awaresg, wrong, male, point, view, felt, exclud, even, non, repli, thread]   \n",
       "99975                                          [cuz, big, burli, man, hahahahahahahahaha]   \n",
       "99976  [tri, get, wider, rang, shirt, suit, everyon, pleas, make, request, need, awaresg]   \n",
       "99977                                                      [haha, love, passion, support]   \n",
       "99978                           [suck, like, live, coopersvil, need, special, bag, anyth]   \n",
       "99979                                                 [till, go, home, till, saturday, x]   \n",
       "99980                                                            [afternoon, jim, how, x]   \n",
       "99981                      [tea, foot, realli, bad, like, worst, ever, bare, walk, right]   \n",
       "99982                              [kati, fun, health, safeti, switch, look, sprite, xxx]   \n",
       "99983                       [took, waaay, long, get, messag, asham, right, realli, asham]   \n",
       "99984                              [seem, like, repeat, problem, hope, abl, find, someth]   \n",
       "99985                         [arrr, repli, differ, tweet, time, see, duno, hell, kateyi]   \n",
       "99986                                                                       [ya, thought]   \n",
       "99987                                                          [dolli, ye, ye, glad, fun]   \n",
       "99988                                                                   [kayla, haha, ye]   \n",
       "\n",
       "                                                                      normal  \n",
       "99969                                                                  sorri  \n",
       "99970                                                          damn dont sky  \n",
       "99971                             thing new raft star war film raft epicfail  \n",
       "99972                                                                         \n",
       "99973                                                           followfriday  \n",
       "99974        awaresg wrong male point view felt exclud even non repli thread  \n",
       "99975                                   cuz big burli man hahahahahahahahaha  \n",
       "99976  tri get wider rang shirt suit everyon pleas make request need awaresg  \n",
       "99977                                              haha love passion support  \n",
       "99978                       suck like live coopersvil need special bag anyth  \n",
       "99979                                           till go home till saturday x  \n",
       "99980                                                    afternoon jim how x  \n",
       "99981                    tea foot realli bad like worst ever bare walk right  \n",
       "99982                          kati fun health safeti switch look sprite xxx  \n",
       "99983                    took waaay long get messag asham right realli asham  \n",
       "99984                          seem like repeat problem hope abl find someth  \n",
       "99985                      arrr repli differ tweet time see duno hell kateyi  \n",
       "99986                                                             ya thought  \n",
       "99987                                                   dolli ye ye glad fun  \n",
       "99988                                                          kayla haha ye  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99989, 405288)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer  \n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "vectorized_data =count_vectorizer.fit_transform(train['normal'])\n",
    "\n",
    "tfidfconverter = TfidfTransformer()  \n",
    "tfid_data = tfidfconverter.fit_transform(vectorized_data)\n",
    "\n",
    "indexed_data =hstack((np.array(range(0,tfid_data.shape[0]))[:,None],tfid_data))\n",
    "\n",
    "#vectorizer = TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "#final_features = vectorizer.fit_transform(train['normal'])\n",
    "\n",
    "#indexed_data =hstack((np.array(range(0,vectorized_data.shape[0]))[:,None],vectorized_data))\n",
    "#indexed_data =hstack((np.array(range(0,final_features.shape[0]))[:,None],final_features))\n",
    "\n",
    "#vectorized_data.shape\n",
    "tfid_data.shape\n",
    "#final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = train.iloc[:, 1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "data_train, data_test, targets_train, targets_test =train_test_split(indexed_data, targets, test_size=0.2,random_state=100)\n",
    "data_train_index = data_train[:,0]\n",
    "data_train = data_train[:,1:]\n",
    "data_test_index = data_test[:,0]\n",
    "data_test = data_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbc = MultinomialNB(fit_prior=True, alpha=1.0).fit(data_train, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5875 2806]\n",
      " [2464 8853]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69      8681\n",
      "           1       0.76      0.78      0.77     11317\n",
      "\n",
      "    accuracy                           0.74     19998\n",
      "   macro avg       0.73      0.73      0.73     19998\n",
      "weighted avg       0.74      0.74      0.74     19998\n",
      "\n",
      "0.7364736473647365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, classification_report\n",
    "\n",
    "nb_pred = nbc.predict(data_test)\n",
    "\n",
    "print(confusion_matrix(targets_test, nb_pred))\n",
    "print(classification_report(targets_test,nb_pred))\n",
    "print(accuracy_score(targets_test, nb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################linear svm\n",
    "from sklearn.svm import LinearSVC\n",
    "lsvm= LinearSVC(C=1.0)\n",
    "lsvm.fit(data_train, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5730 2951]\n",
      " [2390 8927]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68      8681\n",
      "           1       0.75      0.79      0.77     11317\n",
      "\n",
      "    accuracy                           0.73     19998\n",
      "   macro avg       0.73      0.72      0.73     19998\n",
      "weighted avg       0.73      0.73      0.73     19998\n",
      "\n",
      "0.7329232923292329\n"
     ]
    }
   ],
   "source": [
    "targets_pred = lsvm.predict(data_test)\n",
    "\n",
    "print(confusion_matrix(targets_test, targets_pred))\n",
    "print(classification_report(targets_test,targets_pred))\n",
    "print(accuracy_score(targets_test, targets_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################################################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lrc = LogisticRegression(random_state=0)\n",
    "lrc.fit(data_train, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5682 2999]\n",
      " [2009 9308]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.65      0.69      8681\n",
      "           1       0.76      0.82      0.79     11317\n",
      "\n",
      "    accuracy                           0.75     19998\n",
      "   macro avg       0.75      0.74      0.74     19998\n",
      "weighted avg       0.75      0.75      0.75     19998\n",
      "\n",
      "0.7495749574957495\n"
     ]
    }
   ],
   "source": [
    "targets_pred = lrc.predict(data_test)\n",
    "\n",
    "print(confusion_matrix(targets_test, targets_pred))\n",
    "print(classification_report(targets_test,targets_pred))\n",
    "print(accuracy_score(targets_test, targets_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################################################\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=0, max_depth=100)\n",
    "rfc.fit(data_train, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2370  6311]\n",
      " [  372 10945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.27      0.41      8681\n",
      "           1       0.63      0.97      0.77     11317\n",
      "\n",
      "    accuracy                           0.67     19998\n",
      "   macro avg       0.75      0.62      0.59     19998\n",
      "weighted avg       0.73      0.67      0.61     19998\n",
      "\n",
      "0.6658165816581658\n"
     ]
    }
   ],
   "source": [
    "rfy_pred = rfc.predict(data_test)\n",
    "\n",
    "print(confusion_matrix(targets_test, rfy_pred))\n",
    "print(classification_report(targets_test, rfy_pred))\n",
    "print(accuracy_score(targets_test, rfy_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0}\n",
      "0.7461089834370678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hiperparameters = {'C': (0.01,0.1,1.0,10.0,100.0)}\n",
    "grid = GridSearchCV(LogisticRegression(), hiperparameters, cv=3)\n",
    "grid.fit(data_train, targets_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 2.0, 'fit_prior': True}\n",
      "0.7392831977193143\n"
     ]
    }
   ],
   "source": [
    "hiperparameters = {'alpha': (1.0,1.5,2.0,2.5,3.0),'fit_prior':[True, False]}\n",
    "grid = GridSearchCV(MultinomialNB(), hiperparameters, cv=3)\n",
    "grid.fit(data_train, targets_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB(fit_prior=True, alpha=2.0).fit(data_train, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5472 3209]\n",
      " [1959 9358]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68      8681\n",
      "           1       0.74      0.83      0.78     11317\n",
      "\n",
      "    accuracy                           0.74     19998\n",
      "   macro avg       0.74      0.73      0.73     19998\n",
      "weighted avg       0.74      0.74      0.74     19998\n",
      "\n",
      "0.7415741574157416\n"
     ]
    }
   ],
   "source": [
    "nb_pred = nb.predict(data_test)\n",
    "\n",
    "print(confusion_matrix(targets_test, nb_pred))\n",
    "print(classification_report(targets_test,nb_pred))\n",
    "print(accuracy_score(targets_test, nb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1}\n",
      "0.7446713293577417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "hiperparameters = {'C': (0.01,0.1,1.0,5.0,10.0)}\n",
    "grid = GridSearchCV(LinearSVC(), hiperparameters, cv=3)\n",
    "grid.fit(data_train, targets_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guilh_000\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc= LinearSVC(C=0.1)\n",
    "lsvc.fit(data_train, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5596 3085]\n",
      " [1992 9325]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.69      8681\n",
      "           1       0.75      0.82      0.79     11317\n",
      "\n",
      "    accuracy                           0.75     19998\n",
      "   macro avg       0.74      0.73      0.74     19998\n",
      "weighted avg       0.75      0.75      0.74     19998\n",
      "\n",
      "0.7461246124612462\n"
     ]
    }
   ],
   "source": [
    "targets_pred = lsvc.predict(data_test)\n",
    "\n",
    "print(confusion_matrix(targets_test, targets_pred))\n",
    "print(classification_report(targets_test,targets_pred))\n",
    "print(accuracy_score(targets_test, targets_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Linear regression wins\n",
    "######################################################### test model with new data\n",
    "test = pd.read_csv('C:\\\\Users\\\\guilh_000\\\\Documents\\\\tweetsclassify\\\\testing.csv')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['normalized'] = test.Text.apply(clean_tweets)\n",
    "test['normal'] = [' '.join(map(str, l)) for l in test['normalized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>normalized</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am feeling so depressed</td>\n",
       "      <td>0</td>\n",
       "      <td>[feel, depress]</td>\n",
       "      <td>feel depress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I'm so sad. i can't stop crying</td>\n",
       "      <td>0</td>\n",
       "      <td>[sad, stop, cri]</td>\n",
       "      <td>sad stop cri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I don't feel good at all</td>\n",
       "      <td>0</td>\n",
       "      <td>[feel, good]</td>\n",
       "      <td>feel good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I dont feel good at all</td>\n",
       "      <td>0</td>\n",
       "      <td>[dont, feel, good]</td>\n",
       "      <td>dont feel good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm feeling so good</td>\n",
       "      <td>1</td>\n",
       "      <td>[feel, good]</td>\n",
       "      <td>feel good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>If I just breath now And close my eyes Maybe it'll go away #depression #mentalhealth #MentalHeal...</td>\n",
       "      <td>0</td>\n",
       "      <td>[breath, close, eye, mayb, go, away, depress, mentalhealth, mentalhealthawar]</td>\n",
       "      <td>breath close eye mayb go away depress mentalhealth mentalhealthawar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>I am not sad I'm depressed all of a sudden I get this urge feeling of sadness I hope I can stop ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[sad, depress, sudden, get, urg, feel, sad, hope, stop, believ, fuckin, loop, trap, deep, depres...</td>\n",
       "      <td>sad depress sudden get urg feel sad hope stop believ fuckin loop trap deep depress sad help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>I got the job I wanted. I'm really happy right now :)</td>\n",
       "      <td>1</td>\n",
       "      <td>[got, job, want, realli, happi, right]</td>\n",
       "      <td>got job want realli happi right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Holidays can't come soon enough</td>\n",
       "      <td>1</td>\n",
       "      <td>[holiday, come, soon, enough]</td>\n",
       "      <td>holiday come soon enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>My anxiety has been extremely bad lately. If you are suffering, you are not alone</td>\n",
       "      <td>0</td>\n",
       "      <td>[anxieti, extrem, bad, late, suffer, alon]</td>\n",
       "      <td>anxieti extrem bad late suffer alon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TweetID  \\\n",
       "0        1   \n",
       "1        2   \n",
       "2        3   \n",
       "3        4   \n",
       "4        5   \n",
       "5        6   \n",
       "6        7   \n",
       "7        8   \n",
       "8        9   \n",
       "9       10   \n",
       "\n",
       "                                                                                                  Text  \\\n",
       "0                                                                           I am feeling so depressed    \n",
       "1                                                                      I'm so sad. i can't stop crying   \n",
       "2                                                                             I don't feel good at all   \n",
       "3                                                                              I dont feel good at all   \n",
       "4                                                                                  I'm feeling so good   \n",
       "5  If I just breath now And close my eyes Maybe it'll go away #depression #mentalhealth #MentalHeal...   \n",
       "6  I am not sad I'm depressed all of a sudden I get this urge feeling of sadness I hope I can stop ...   \n",
       "7                                                I got the job I wanted. I'm really happy right now :)   \n",
       "8                                                                      Holidays can't come soon enough   \n",
       "9                    My anxiety has been extremely bad lately. If you are suffering, you are not alone   \n",
       "\n",
       "   Label  \\\n",
       "0      0   \n",
       "1      0   \n",
       "2      0   \n",
       "3      0   \n",
       "4      1   \n",
       "5      0   \n",
       "6      0   \n",
       "7      1   \n",
       "8      1   \n",
       "9      0   \n",
       "\n",
       "                                                                                            normalized  \\\n",
       "0                                                                                      [feel, depress]   \n",
       "1                                                                                     [sad, stop, cri]   \n",
       "2                                                                                         [feel, good]   \n",
       "3                                                                                   [dont, feel, good]   \n",
       "4                                                                                         [feel, good]   \n",
       "5                        [breath, close, eye, mayb, go, away, depress, mentalhealth, mentalhealthawar]   \n",
       "6  [sad, depress, sudden, get, urg, feel, sad, hope, stop, believ, fuckin, loop, trap, deep, depres...   \n",
       "7                                                               [got, job, want, realli, happi, right]   \n",
       "8                                                                        [holiday, come, soon, enough]   \n",
       "9                                                           [anxieti, extrem, bad, late, suffer, alon]   \n",
       "\n",
       "                                                                                        normal  \n",
       "0                                                                                 feel depress  \n",
       "1                                                                                 sad stop cri  \n",
       "2                                                                                    feel good  \n",
       "3                                                                               dont feel good  \n",
       "4                                                                                    feel good  \n",
       "5                          breath close eye mayb go away depress mentalhealth mentalhealthawar  \n",
       "6  sad depress sudden get urg feel sad hope stop believ fuckin loop trap deep depress sad help  \n",
       "7                                                              got job want realli happi right  \n",
       "8                                                                     holiday come soon enough  \n",
       "9                                                          anxieti extrem bad late suffer alon  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_to_predict = test['normal']\n",
    "x = count_vectorizer.transform(tweet_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Prediction'] = lrc.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>normalized</th>\n",
       "      <th>normal</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am feeling so depressed</td>\n",
       "      <td>0</td>\n",
       "      <td>[feel, depress]</td>\n",
       "      <td>feel depress</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I'm so sad. i can't stop crying</td>\n",
       "      <td>0</td>\n",
       "      <td>[sad, stop, cri]</td>\n",
       "      <td>sad stop cri</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I don't feel good at all</td>\n",
       "      <td>0</td>\n",
       "      <td>[feel, good]</td>\n",
       "      <td>feel good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I dont feel good at all</td>\n",
       "      <td>0</td>\n",
       "      <td>[dont, feel, good]</td>\n",
       "      <td>dont feel good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm feeling so good</td>\n",
       "      <td>1</td>\n",
       "      <td>[feel, good]</td>\n",
       "      <td>feel good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>If I just breath now And close my eyes Maybe it'll go away #depression #mentalhealth #MentalHeal...</td>\n",
       "      <td>0</td>\n",
       "      <td>[breath, close, eye, mayb, go, away, depress, mentalhealth, mentalhealthawar]</td>\n",
       "      <td>breath close eye mayb go away depress mentalhealth mentalhealthawar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>I am not sad I'm depressed all of a sudden I get this urge feeling of sadness I hope I can stop ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[sad, depress, sudden, get, urg, feel, sad, hope, stop, believ, fuckin, loop, trap, deep, depres...</td>\n",
       "      <td>sad depress sudden get urg feel sad hope stop believ fuckin loop trap deep depress sad help</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>I got the job I wanted. I'm really happy right now :)</td>\n",
       "      <td>1</td>\n",
       "      <td>[got, job, want, realli, happi, right]</td>\n",
       "      <td>got job want realli happi right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Holidays can't come soon enough</td>\n",
       "      <td>1</td>\n",
       "      <td>[holiday, come, soon, enough]</td>\n",
       "      <td>holiday come soon enough</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>My anxiety has been extremely bad lately. If you are suffering, you are not alone</td>\n",
       "      <td>0</td>\n",
       "      <td>[anxieti, extrem, bad, late, suffer, alon]</td>\n",
       "      <td>anxieti extrem bad late suffer alon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Our zoom meeting went really well today</td>\n",
       "      <td>1</td>\n",
       "      <td>[zoom, meet, went, realli, well, today]</td>\n",
       "      <td>zoom meet went realli well today</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Just tried this new corona beer and it's the best thing ever omg</td>\n",
       "      <td>1</td>\n",
       "      <td>[tri, new, corona, beer, best, thing, ever, omg]</td>\n",
       "      <td>tri new corona beer best thing ever omg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>I hate to say this, but I doubt I'll ever come back to this restaurant</td>\n",
       "      <td>0</td>\n",
       "      <td>[hate, say, doubt, ever, come, back, restaur]</td>\n",
       "      <td>hate say doubt ever come back restaur</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Food was so good and the staff was cordial</td>\n",
       "      <td>1</td>\n",
       "      <td>[food, good, staff, cordial]</td>\n",
       "      <td>food good staff cordial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Just ordered a book from Amazon</td>\n",
       "      <td>1</td>\n",
       "      <td>[order, book, amazon]</td>\n",
       "      <td>order book amazon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>I'm feeling sad</td>\n",
       "      <td>0</td>\n",
       "      <td>[feel, sad]</td>\n",
       "      <td>feel sad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>I'm not feeling sad</td>\n",
       "      <td>1</td>\n",
       "      <td>[feel, sad]</td>\n",
       "      <td>feel sad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>I knew you Playing hide-and-seek and Giving me your weekends</td>\n",
       "      <td>1</td>\n",
       "      <td>[knew, play, hide, seek, give, weekend]</td>\n",
       "      <td>knew play hide seek give weekend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>I knew you Your heartbeat on the High Line Once in twenty lifetimes, I</td>\n",
       "      <td>1</td>\n",
       "      <td>[knew, heartbeat, high, line, twenti, lifetim]</td>\n",
       "      <td>knew heartbeat high line twenti lifetim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>When you are young they assume you know nothing</td>\n",
       "      <td>0</td>\n",
       "      <td>[young, assum, know, noth]</td>\n",
       "      <td>young assum know noth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>You heard the rumors from Inez You can't believe a word she says Most times, but this time it wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>[heard, rumor, inez, believ, word, say, time, time, true, worst, thing, ever]</td>\n",
       "      <td>heard rumor inez believ word say time time true worst thing ever</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TweetID  \\\n",
       "0         1   \n",
       "1         2   \n",
       "2         3   \n",
       "3         4   \n",
       "4         5   \n",
       "5         6   \n",
       "6         7   \n",
       "7         8   \n",
       "8         9   \n",
       "9        10   \n",
       "10       11   \n",
       "11       12   \n",
       "12       13   \n",
       "13       14   \n",
       "14       15   \n",
       "15       16   \n",
       "16       17   \n",
       "17       18   \n",
       "18       19   \n",
       "19       20   \n",
       "20       21   \n",
       "\n",
       "                                                                                                   Text  \\\n",
       "0                                                                            I am feeling so depressed    \n",
       "1                                                                       I'm so sad. i can't stop crying   \n",
       "2                                                                              I don't feel good at all   \n",
       "3                                                                               I dont feel good at all   \n",
       "4                                                                                   I'm feeling so good   \n",
       "5   If I just breath now And close my eyes Maybe it'll go away #depression #mentalhealth #MentalHeal...   \n",
       "6   I am not sad I'm depressed all of a sudden I get this urge feeling of sadness I hope I can stop ...   \n",
       "7                                                 I got the job I wanted. I'm really happy right now :)   \n",
       "8                                                                       Holidays can't come soon enough   \n",
       "9                     My anxiety has been extremely bad lately. If you are suffering, you are not alone   \n",
       "10                                                              Our zoom meeting went really well today   \n",
       "11                                     Just tried this new corona beer and it's the best thing ever omg   \n",
       "12                               I hate to say this, but I doubt I'll ever come back to this restaurant   \n",
       "13                                                           Food was so good and the staff was cordial   \n",
       "14                                                                      Just ordered a book from Amazon   \n",
       "15                                                                                      I'm feeling sad   \n",
       "16                                                                                  I'm not feeling sad   \n",
       "17                                         I knew you Playing hide-and-seek and Giving me your weekends   \n",
       "18                               I knew you Your heartbeat on the High Line Once in twenty lifetimes, I   \n",
       "19                                                      When you are young they assume you know nothing   \n",
       "20  You heard the rumors from Inez You can't believe a word she says Most times, but this time it wa...   \n",
       "\n",
       "    Label  \\\n",
       "0       0   \n",
       "1       0   \n",
       "2       0   \n",
       "3       0   \n",
       "4       1   \n",
       "5       0   \n",
       "6       0   \n",
       "7       1   \n",
       "8       1   \n",
       "9       0   \n",
       "10      1   \n",
       "11      1   \n",
       "12      0   \n",
       "13      1   \n",
       "14      1   \n",
       "15      0   \n",
       "16      1   \n",
       "17      1   \n",
       "18      1   \n",
       "19      0   \n",
       "20      0   \n",
       "\n",
       "                                                                                             normalized  \\\n",
       "0                                                                                       [feel, depress]   \n",
       "1                                                                                      [sad, stop, cri]   \n",
       "2                                                                                          [feel, good]   \n",
       "3                                                                                    [dont, feel, good]   \n",
       "4                                                                                          [feel, good]   \n",
       "5                         [breath, close, eye, mayb, go, away, depress, mentalhealth, mentalhealthawar]   \n",
       "6   [sad, depress, sudden, get, urg, feel, sad, hope, stop, believ, fuckin, loop, trap, deep, depres...   \n",
       "7                                                                [got, job, want, realli, happi, right]   \n",
       "8                                                                         [holiday, come, soon, enough]   \n",
       "9                                                            [anxieti, extrem, bad, late, suffer, alon]   \n",
       "10                                                              [zoom, meet, went, realli, well, today]   \n",
       "11                                                     [tri, new, corona, beer, best, thing, ever, omg]   \n",
       "12                                                        [hate, say, doubt, ever, come, back, restaur]   \n",
       "13                                                                         [food, good, staff, cordial]   \n",
       "14                                                                                [order, book, amazon]   \n",
       "15                                                                                          [feel, sad]   \n",
       "16                                                                                          [feel, sad]   \n",
       "17                                                              [knew, play, hide, seek, give, weekend]   \n",
       "18                                                       [knew, heartbeat, high, line, twenti, lifetim]   \n",
       "19                                                                           [young, assum, know, noth]   \n",
       "20                        [heard, rumor, inez, believ, word, say, time, time, true, worst, thing, ever]   \n",
       "\n",
       "                                                                                         normal  \\\n",
       "0                                                                                  feel depress   \n",
       "1                                                                                  sad stop cri   \n",
       "2                                                                                     feel good   \n",
       "3                                                                                dont feel good   \n",
       "4                                                                                     feel good   \n",
       "5                           breath close eye mayb go away depress mentalhealth mentalhealthawar   \n",
       "6   sad depress sudden get urg feel sad hope stop believ fuckin loop trap deep depress sad help   \n",
       "7                                                               got job want realli happi right   \n",
       "8                                                                      holiday come soon enough   \n",
       "9                                                           anxieti extrem bad late suffer alon   \n",
       "10                                                             zoom meet went realli well today   \n",
       "11                                                      tri new corona beer best thing ever omg   \n",
       "12                                                        hate say doubt ever come back restaur   \n",
       "13                                                                      food good staff cordial   \n",
       "14                                                                            order book amazon   \n",
       "15                                                                                     feel sad   \n",
       "16                                                                                     feel sad   \n",
       "17                                                             knew play hide seek give weekend   \n",
       "18                                                      knew heartbeat high line twenti lifetim   \n",
       "19                                                                        young assum know noth   \n",
       "20                             heard rumor inez believ word say time time true worst thing ever   \n",
       "\n",
       "    Prediction  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "5            0  \n",
       "6            0  \n",
       "7            1  \n",
       "8            1  \n",
       "9            0  \n",
       "10           1  \n",
       "11           1  \n",
       "12           0  \n",
       "13           1  \n",
       "14           1  \n",
       "15           0  \n",
       "16           0  \n",
       "17           1  \n",
       "18           1  \n",
       "19           1  \n",
       "20           0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  1]\n",
      " [ 2  8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        11\n",
      "           1       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.86        21\n",
      "   macro avg       0.86      0.85      0.86        21\n",
      "weighted avg       0.86      0.86      0.86        21\n",
      "\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test['Label'], test['Prediction']))\n",
    "print(classification_report(test['Label'], test['Prediction']))\n",
    "print(accuracy_score(test['Label'], test['Prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tdif test\n",
    "lrtdif = LogisticRegression(random_state=0)\n",
    "lrtdif.fit(data_train, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5442 3239]\n",
      " [1735 9582]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.63      0.69      8681\n",
      "           1       0.75      0.85      0.79     11317\n",
      "\n",
      "    accuracy                           0.75     19998\n",
      "   macro avg       0.75      0.74      0.74     19998\n",
      "weighted avg       0.75      0.75      0.75     19998\n",
      "\n",
      "0.7512751275127513\n"
     ]
    }
   ],
   "source": [
    "targets_pred = lrtdif.predict(data_test)\n",
    "\n",
    "print(confusion_matrix(targets_test, targets_pred))\n",
    "print(classification_report(targets_test,targets_pred))\n",
    "print(accuracy_score(targets_test, targets_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[5682 2999]\n",
    " [2009 9308]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.74      0.65      0.69      8681\n",
    "           1       0.76      0.82      0.79     11317\n",
    "\n",
    "    accuracy                           0.75     19998\n",
    "   macro avg       0.75      0.74      0.74     19998\n",
    "weighted avg       0.75      0.75      0.75     19998\n",
    "\n",
    "0.7495749574957495"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
